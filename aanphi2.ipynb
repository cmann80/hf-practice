{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf89d5da6624abfac0757d9e268df01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what's the weather like down there? I feel like everything's just so different,\" Emma mused as she twirled a straw in her cocktail.\n",
      "\n",
      "\"Well, it depends on which hemisphere you're in. Down under, it's like summer while on the other side of the world, winter is just around the corner,\" David explained, grinning.\n",
      "\n",
      "Emma shook her head with a chuckle. \"It's crazy to think how such a small change in tilt can affect our entire seasons. I mean, it's like\n"
     ]
    }
   ],
   "source": [
    "prompt = input()\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "device = \"cuda\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mobiuslabsgmbh/aanaphi2-v0.1\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mobiuslabsgmbh/aanaphi2-v0.1\")\n",
    "\n",
    "model = model.half()\n",
    "\n",
    "model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(device)\n",
    "model.to(device)\n",
    "\n",
    "generated_ids = model.generate(**model_inputs, max_new_tokens=100, do_sample=True)\n",
    "result = tokenizer.batch_decode(generated_ids)[0]\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
